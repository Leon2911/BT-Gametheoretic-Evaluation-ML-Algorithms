## Simulationslauf vom: 2025-11-25 18:08:20

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `59.36%`
- **Durchschnittliche Kooperationsrate:** `26.45%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 355.09

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 41.0%
  - `Polarized`: 16.5%
  - `Cautious Coop.`: 16.5%
  - `Cooperator (ALLC)`: 11.5%
  - `TFT-like`: 10.5%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1
  - `Cooperator (ALLC)`: 1
  - `TFT-like`: 1

---

## Simulationslauf vom: 2025-11-25 18:24:05

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `1`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `57.39%`
- **Durchschnittliche Kooperationsrate:** `24.32%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 344.93

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.5%
  - `Polarized`: 19.5%
  - `Cooperator (ALLC)`: 14.0%
  - `Cautious Coop.`: 8.5%
  - `TFT-like`: 7.0%
  - `WSLS`: 2.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-25 18:45:45

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `2`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.93%`
- **Durchschnittliche Kooperationsrate:** `24.13%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 342.18

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 44.0%
  - `Polarized`: 21.0%
  - `Cautious Coop.`: 13.0%
  - `Cooperator (ALLC)`: 10.0%
  - `TFT-like`: 9.0%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-11-25 19:06:17

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `3`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `57.32%`
- **Durchschnittliche Kooperationsrate:** `25.08%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 342.66

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.0%
  - `Polarized`: 14.5%
  - `Cautious Coop.`: 14.5%
  - `Cooperator (ALLC)`: 10.5%
  - `TFT-like`: 9.0%
  - `WSLS`: 3.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2
  - `TFT-like`: 1

---

## Simulationslauf vom: 2025-11-25 19:21:52

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `4`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.77%`
- **Durchschnittliche Kooperationsrate:** `26.29%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 352.41

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `10`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 41.0%
  - `Cautious Coop.`: 27.5%
  - `TFT-like`: 12.5%
  - `Polarized`: 8.0%
  - `Cooperator (ALLC)`: 7.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 7
  - `TFT-like`: 2
  - `Cooperator (ALLC)`: 1

---

## Simulationslauf vom: 2025-11-25 19:42:14

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `5`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.79%`
- **Durchschnittliche Kooperationsrate:** `23.72%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 340.65

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 39.0%
  - `Cautious Coop.`: 23.0%
  - `TFT-like`: 12.5%
  - `Polarized`: 10.5%
  - `Cooperator (ALLC)`: 10.0%
  - `WSLS`: 5.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2

---

## Simulationslauf vom: 2025-11-25 19:58:18

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `6`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.02%`
- **Durchschnittliche Kooperationsrate:** `25.27%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 347.35

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 43.0%
  - `Polarized`: 17.5%
  - `Cautious Coop.`: 15.0%
  - `Cooperator (ALLC)`: 11.0%
  - `TFT-like`: 10.5%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1
  - `Cooperator (ALLC)`: 1
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-26 14:14:50

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `7`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.59%`
- **Durchschnittliche Kooperationsrate:** `23.12%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.56

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 46.5%
  - `Polarized`: 22.0%
  - `Cautious Coop.`: 12.5%
  - `Cooperator (ALLC)`: 9.5%
  - `TFT-like`: 8.0%
  - `WSLS`: 1.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-26 14:28:13

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `8`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.52%`
- **Durchschnittliche Kooperationsrate:** `23.69%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.57

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 42.0%
  - `Polarized`: 22.0%
  - `Cooperator (ALLC)`: 11.0%
  - `TFT-like`: 11.0%
  - `Cautious Coop.`: 10.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-26 14:43:34

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.58%`
- **Durchschnittliche Kooperationsrate:** `23.59%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.57

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.5%
  - `Polarized`: 15.5%
  - `Cautious Coop.`: 14.0%
  - `TFT-like`: 12.0%
  - `Cooperator (ALLC)`: 7.0%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2

---

## Simulationslauf vom: 2025-11-26 19:25:16

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `59.36%`
- **Durchschnittliche Kooperationsrate:** `26.45%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 355.09

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 41.0%
  - `Polarized`: 16.5%
  - `Cautious Coop.`: 16.5%
  - `Cooperator (ALLC)`: 11.5%
  - `TFT-like`: 10.5%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1
  - `Cooperator (ALLC)`: 1
  - `TFT-like`: 1

---

## Simulationslauf vom: 2025-11-27 13:06:31

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(25, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `500`
- **Gesamt:** `500` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-27 13:06:45

### Globale Parameter
- **Begegnungsschema:** `RandomPairingScheme`
- **Gittergröße:** `N/A`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `500`
- **Gesamt:** `500` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `50.89%`
- **Durchschnittliche Kooperationsrate:** `19.46%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 305.28

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 62.6%
  - `Cautious Coop.`: 11.8%
  - `Polarized`: 11.2%
  - `TFT-like`: 7.6%
  - `Cooperator (ALLC)`: 5.6%
  - `WSLS`: 1.2%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-27 17:46:58

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(25, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `500`
- **Gesamt:** `500` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-27 17:47:14

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(25, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `500`
- **Gesamt:** `500` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `55.62%`
- **Durchschnittliche Kooperationsrate:** `22.05%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 332.90

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 55.4%
  - `Polarized`: 17.6%
  - `Cooperator (ALLC)`: 9.4%
  - `Cautious Coop.`: 9.2%
  - `TFT-like`: 6.2%
  - `WSLS`: 2.2%
- **Anzahl Cluster pro Strategietyp:**
  - `WSLS`: 1

---

## Simulationslauf vom: 2025-11-27 18:03:04

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `59.36%`
- **Durchschnittliche Kooperationsrate:** `26.45%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 355.09

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 41.0%
  - `Polarized`: 16.5%
  - `Cautious Coop.`: 16.5%
  - `Cooperator (ALLC)`: 11.5%
  - `TFT-like`: 10.5%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1
  - `Cooperator (ALLC)`: 1
  - `TFT-like`: 1

---

## Simulationslauf vom: 2025-11-27 18:19:25

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-27 18:19:31

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `1`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `57.39%`
- **Durchschnittliche Kooperationsrate:** `24.32%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 344.93

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.5%
  - `Polarized`: 19.5%
  - `Cooperator (ALLC)`: 14.0%
  - `Cautious Coop.`: 8.5%
  - `TFT-like`: 7.0%
  - `WSLS`: 2.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-27 18:39:25

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `2`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.93%`
- **Durchschnittliche Kooperationsrate:** `24.13%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 342.18

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 44.0%
  - `Polarized`: 21.0%
  - `Cautious Coop.`: 13.0%
  - `Cooperator (ALLC)`: 10.0%
  - `TFT-like`: 9.0%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-11-27 19:11:19

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `3`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `57.32%`
- **Durchschnittliche Kooperationsrate:** `25.08%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 342.66

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.0%
  - `Polarized`: 14.5%
  - `Cautious Coop.`: 14.5%
  - `Cooperator (ALLC)`: 10.5%
  - `TFT-like`: 9.0%
  - `WSLS`: 3.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2
  - `TFT-like`: 1

---

## Simulationslauf vom: 2025-11-27 20:19:41

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `4`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.77%`
- **Durchschnittliche Kooperationsrate:** `26.29%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 352.41

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `10`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 41.0%
  - `Cautious Coop.`: 27.5%
  - `TFT-like`: 12.5%
  - `Polarized`: 8.0%
  - `Cooperator (ALLC)`: 7.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 7
  - `TFT-like`: 2
  - `Cooperator (ALLC)`: 1

---

## Simulationslauf vom: 2025-11-27 21:05:15

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `5`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.79%`
- **Durchschnittliche Kooperationsrate:** `23.72%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 340.65

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 39.0%
  - `Cautious Coop.`: 23.0%
  - `TFT-like`: 12.5%
  - `Polarized`: 10.5%
  - `Cooperator (ALLC)`: 10.0%
  - `WSLS`: 5.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2

---

## Simulationslauf vom: 2025-11-27 22:18:38

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `6`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.02%`
- **Durchschnittliche Kooperationsrate:** `25.27%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 347.35

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 43.0%
  - `Polarized`: 17.5%
  - `Cautious Coop.`: 15.0%
  - `Cooperator (ALLC)`: 11.0%
  - `TFT-like`: 10.5%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1
  - `Cooperator (ALLC)`: 1
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 10:49:22

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `7`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.59%`
- **Durchschnittliche Kooperationsrate:** `23.12%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.56

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 46.5%
  - `Polarized`: 22.0%
  - `Cautious Coop.`: 12.5%
  - `Cooperator (ALLC)`: 9.5%
  - `TFT-like`: 8.0%
  - `WSLS`: 1.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 11:07:07

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `8`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.52%`
- **Durchschnittliche Kooperationsrate:** `23.69%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.57

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 42.0%
  - `Polarized`: 22.0%
  - `Cooperator (ALLC)`: 11.0%
  - `TFT-like`: 11.0%
  - `Cautious Coop.`: 10.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 11:47:48

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.58%`
- **Durchschnittliche Kooperationsrate:** `23.59%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.57

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.5%
  - `Polarized`: 15.5%
  - `Cautious Coop.`: 14.0%
  - `TFT-like`: 12.0%
  - `Cooperator (ALLC)`: 7.0%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2

---

## Simulationslauf vom: 2025-11-28 16:04:23

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-28 16:05:13

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-28 16:06:04

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-28 16:06:21

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-28 16:06:33

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-28 16:06:41

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-28 16:07:13

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-28 16:09:30

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-28 16:17:46

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `60.80%`
- **Durchschnittliche Kooperationsrate:** `27.19%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 365.00

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 39.0%
  - `Polarized`: 21.0%
  - `Cooperator (ALLC)`: 17.5%
  - `Cautious Coop.`: 11.5%
  - `TFT-like`: 9.0%
  - `WSLS`: 2.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 16:36:59

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `1`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `60.52%`
- **Durchschnittliche Kooperationsrate:** `27.61%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 362.10

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 40.5%
  - `Polarized`: 24.5%
  - `TFT-like`: 11.5%
  - `Cooperator (ALLC)`: 11.0%
  - `Cautious Coop.`: 9.5%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 16:52:38

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `2`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `61.20%`
- **Durchschnittliche Kooperationsrate:** `27.41%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 368.15

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 36.0%
  - `Polarized`: 21.5%
  - `Cooperator (ALLC)`: 17.5%
  - `Cautious Coop.`: 11.5%
  - `TFT-like`: 9.5%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1
  - `WSLS`: 1

---

## Simulationslauf vom: 2025-11-28 17:06:01

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `3`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `60.72%`
- **Durchschnittliche Kooperationsrate:** `26.91%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 362.37

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 41.0%
  - `Polarized`: 20.0%
  - `Cooperator (ALLC)`: 14.0%
  - `Cautious Coop.`: 12.0%
  - `TFT-like`: 10.0%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 17:18:43

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `4`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.94%`
- **Durchschnittliche Kooperationsrate:** `25.22%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 352.79

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 44.5%
  - `Polarized`: 20.5%
  - `Cooperator (ALLC)`: 14.5%
  - `TFT-like`: 9.0%
  - `Cautious Coop.`: 8.0%
  - `WSLS`: 3.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 18:02:24

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `5`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `63.75%`
- **Durchschnittliche Kooperationsrate:** `29.93%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 381.11

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 38.5%
  - `Polarized`: 21.5%
  - `TFT-like`: 13.5%
  - `Cautious Coop.`: 12.5%
  - `Cooperator (ALLC)`: 10.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `TFT-like`: 1
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 19:01:18

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `6`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `61.71%`
- **Durchschnittliche Kooperationsrate:** `27.97%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 368.91

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 46.0%
  - `Polarized`: 20.5%
  - `Cooperator (ALLC)`: 11.0%
  - `TFT-like`: 10.0%
  - `Cautious Coop.`: 9.0%
  - `WSLS`: 3.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-11-28 19:51:47

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `7`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `61.69%`
- **Durchschnittliche Kooperationsrate:** `28.56%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 370.08

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 42.0%
  - `Polarized`: 16.5%
  - `TFT-like`: 12.0%
  - `Cautious Coop.`: 12.0%
  - `Cooperator (ALLC)`: 11.0%
  - `WSLS`: 6.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 20:04:57

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `8`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `61.42%`
- **Durchschnittliche Kooperationsrate:** `27.80%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 367.61

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 43.5%
  - `Cooperator (ALLC)`: 16.0%
  - `Polarized`: 15.5%
  - `Cautious Coop.`: 14.5%
  - `TFT-like`: 8.0%
  - `WSLS`: 2.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-28 20:18:27

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `61.05%`
- **Durchschnittliche Kooperationsrate:** `27.02%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 367.02

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 39.0%
  - `Polarized`: 19.5%
  - `Cooperator (ALLC)`: 13.0%
  - `TFT-like`: 12.5%
  - `Cautious Coop.`: 11.5%
  - `WSLS`: 4.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-12-01 12:31:59

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.75%`
- **Durchschnittliche Kooperationsrate:** `31.10%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 354.26

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.0%
  - `Polarized`: 15.5%
  - `Cooperator (ALLC)`: 11.5%
  - `Cautious Coop.`: 10.0%
  - `TFT-like`: 9.5%
  - `WSLS`: 5.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-12-01 13:32:15

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `1`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `60.44%`
- **Durchschnittliche Kooperationsrate:** `32.64%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 363.37

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 49.0%
  - `Cooperator (ALLC)`: 13.0%
  - `Polarized`: 12.0%
  - `Cautious Coop.`: 11.5%
  - `TFT-like`: 7.5%
  - `WSLS`: 7.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Cooperator (ALLC)`: 1
  - `Defector`: 1
  - `WSLS`: 1

---

## Simulationslauf vom: 2025-12-01 14:54:08

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `2`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.92%`
- **Durchschnittliche Kooperationsrate:** `31.57%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 353.31

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 51.0%
  - `Cautious Coop.`: 17.0%
  - `Polarized`: 9.5%
  - `Cooperator (ALLC)`: 9.0%
  - `WSLS`: 8.0%
  - `TFT-like`: 5.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-12-01 15:49:17

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `3`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `57.80%`
- **Durchschnittliche Kooperationsrate:** `30.74%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 346.02

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 49.5%
  - `Cautious Coop.`: 16.5%
  - `Cooperator (ALLC)`: 14.5%
  - `Polarized`: 10.5%
  - `TFT-like`: 5.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-12-01 16:55:46

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `4`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `64.34%`
- **Durchschnittliche Kooperationsrate:** `35.68%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 386.08

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 37.0%
  - `Cautious Coop.`: 20.5%
  - `Cooperator (ALLC)`: 15.0%
  - `WSLS`: 11.0%
  - `TFT-like`: 9.0%
  - `Polarized`: 7.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1
  - `TFT-like`: 1

---

## Simulationslauf vom: 2025-12-01 17:41:17

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `5`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.29%`
- **Durchschnittliche Kooperationsrate:** `31.41%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 351.46

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 50.0%
  - `Cooperator (ALLC)`: 12.5%
  - `Polarized`: 12.5%
  - `Cautious Coop.`: 11.0%
  - `TFT-like`: 9.5%
  - `WSLS`: 4.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-12-01 18:56:31

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `6`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `60.92%`
- **Durchschnittliche Kooperationsrate:** `32.71%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 365.30

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 46.5%
  - `Polarized`: 13.0%
  - `Cautious Coop.`: 12.5%
  - `Cooperator (ALLC)`: 12.5%
  - `WSLS`: 8.5%
  - `TFT-like`: 7.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2
  - `WSLS`: 1

---

## Simulationslauf vom: 2025-12-01 19:43:08

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `7`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `62.00%`
- **Durchschnittliche Kooperationsrate:** `33.88%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 369.43

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `6`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 46.0%
  - `Cautious Coop.`: 18.0%
  - `Cooperator (ALLC)`: 10.5%
  - `TFT-like`: 10.5%
  - `Polarized`: 7.5%
  - `WSLS`: 7.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 4
  - `WSLS`: 1
  - `TFT-like`: 1

---

## Simulationslauf vom: 2025-12-01 20:34:41

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `8`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `61.02%`
- **Durchschnittliche Kooperationsrate:** `33.43%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 366.25

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 43.0%
  - `Cautious Coop.`: 17.0%
  - `Cooperator (ALLC)`: 15.0%
  - `Polarized`: 12.5%
  - `TFT-like`: 7.5%
  - `WSLS`: 5.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2

---

## Simulationslauf vom: 2025-12-01 21:32:22

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QLE:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **temperature:** `50.0`
- **temperature_decay:** `0.9999`
- **min_temperature:** `0.1`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `61.03%`
- **Durchschnittliche Kooperationsrate:** `32.65%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 366.01

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 42.5%
  - `Cautious Coop.`: 15.0%
  - `Cooperator (ALLC)`: 14.0%
  - `Polarized`: 12.0%
  - `WSLS`: 8.5%
  - `TFT-like`: 8.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Cooperator (ALLC)`: 1
  - `Polarized`: 1

---

