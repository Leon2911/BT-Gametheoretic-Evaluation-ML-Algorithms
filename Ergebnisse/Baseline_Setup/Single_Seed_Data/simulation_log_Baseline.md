## Simulationslauf vom: 2025-11-14 00:47:38

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `3`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `57.32%`
- **Durchschnittliche Kooperationsrate:** `25.08%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 342.66

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.0%
  - `Polarized`: 14.5%
  - `Cautious Coop.`: 14.5%
  - `Cooperator (ALLC)`: 10.5%
  - `TFT-like`: 9.0%
  - `WSLS`: 3.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2
  - `TFT-like`: 1

---

## Simulationslauf vom: 2025-11-14 01:03:11

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `2`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.93%`
- **Durchschnittliche Kooperationsrate:** `24.13%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 342.18

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 44.0%
  - `Polarized`: 21.0%
  - `Cautious Coop.`: 13.0%
  - `Cooperator (ALLC)`: 10.0%
  - `TFT-like`: 9.0%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-11-14 01:19:06

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `4`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.77%`
- **Durchschnittliche Kooperationsrate:** `26.29%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 352.41

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `10`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 41.0%
  - `Cautious Coop.`: 27.5%
  - `TFT-like`: 12.5%
  - `Polarized`: 8.0%
  - `Cooperator (ALLC)`: 7.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 7
  - `TFT-like`: 2
  - `Cooperator (ALLC)`: 1

---

## Simulationslauf vom: 2025-11-14 01:37:03

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `5`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.79%`
- **Durchschnittliche Kooperationsrate:** `23.72%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 340.65

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 39.0%
  - `Cautious Coop.`: 23.0%
  - `TFT-like`: 12.5%
  - `Polarized`: 10.5%
  - `Cooperator (ALLC)`: 10.0%
  - `WSLS`: 5.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2

---

## Simulationslauf vom: 2025-11-14 02:08:19

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `6`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `58.02%`
- **Durchschnittliche Kooperationsrate:** `25.27%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 347.35

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `3`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 43.0%
  - `Polarized`: 17.5%
  - `Cautious Coop.`: 15.0%
  - `Cooperator (ALLC)`: 11.0%
  - `TFT-like`: 10.5%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1
  - `Cooperator (ALLC)`: 1
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-14 02:26:16

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `7`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.59%`
- **Durchschnittliche Kooperationsrate:** `23.12%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.56

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 46.5%
  - `Polarized`: 22.0%
  - `Cautious Coop.`: 12.5%
  - `Cooperator (ALLC)`: 9.5%
  - `TFT-like`: 8.0%
  - `WSLS`: 1.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-14 02:47:24

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `8`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.52%`
- **Durchschnittliche Kooperationsrate:** `23.69%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.57

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 42.0%
  - `Polarized`: 22.0%
  - `Cooperator (ALLC)`: 11.0%
  - `TFT-like`: 11.0%
  - `Cautious Coop.`: 10.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-14 03:34:11

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `56.58%`
- **Durchschnittliche Kooperationsrate:** `23.59%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 337.57

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 48.5%
  - `Polarized`: 15.5%
  - `Cautious Coop.`: 14.0%
  - `TFT-like`: 12.0%
  - `Cooperator (ALLC)`: 7.0%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2

---

## Simulationslauf vom: 2025-11-14 05:02:30

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---
