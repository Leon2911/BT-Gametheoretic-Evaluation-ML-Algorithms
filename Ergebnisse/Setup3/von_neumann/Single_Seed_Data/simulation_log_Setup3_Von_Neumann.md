## Simulationslauf vom: 2025-11-25 12:47:38

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `0`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `68.69%`
- **Durchschnittliche Kooperationsrate:** `32.38%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 412.14

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 28.0%
  - `Cooperator (ALLC)`: 20.0%
  - `Polarized`: 18.0%
  - `TFT-like`: 16.0%
  - `Cautious Coop.`: 14.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-25 13:10:40

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `1`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `67.04%`
- **Durchschnittliche Kooperationsrate:** `30.71%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 402.31

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 34.5%
  - `Polarized`: 24.5%
  - `Cooperator (ALLC)`: 20.0%
  - `TFT-like`: 16.0%
  - `Cautious Coop.`: 3.0%
  - `WSLS`: 2.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-25 13:26:08

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `2`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `68.68%`
- **Durchschnittliche Kooperationsrate:** `32.91%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 410.67

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 33.5%
  - `Polarized`: 20.0%
  - `TFT-like`: 18.0%
  - `Cooperator (ALLC)`: 17.5%
  - `Cautious Coop.`: 9.5%
  - `WSLS`: 1.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-25 13:43:03

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `3`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `68.75%`
- **Durchschnittliche Kooperationsrate:** `32.48%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 412.27

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 31.0%
  - `Cooperator (ALLC)`: 21.0%
  - `Polarized`: 19.5%
  - `Cautious Coop.`: 12.5%
  - `TFT-like`: 12.0%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Cooperator (ALLC)`: 1

---

## Simulationslauf vom: 2025-11-25 13:58:50

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `4`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `68.96%`
- **Durchschnittliche Kooperationsrate:** `33.17%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 413.39

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `2`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 39.0%
  - `Cooperator (ALLC)`: 21.0%
  - `Polarized`: 18.0%
  - `TFT-like`: 11.0%
  - `Cautious Coop.`: 8.0%
  - `WSLS`: 3.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 2

---

## Simulationslauf vom: 2025-11-25 14:35:43

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `5`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `67.81%`
- **Durchschnittliche Kooperationsrate:** `32.11%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 406.81

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 33.0%
  - `Cooperator (ALLC)`: 23.5%
  - `Polarized`: 22.5%
  - `Cautious Coop.`: 13.5%
  - `TFT-like`: 7.0%
  - `WSLS`: 0.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-11-25 14:50:13

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `6`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `68.34%`
- **Durchschnittliche Kooperationsrate:** `32.30%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 410.08

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 30.5%
  - `Polarized`: 23.0%
  - `Cooperator (ALLC)`: 21.0%
  - `TFT-like`: 11.0%
  - `Cautious Coop.`: 10.0%
  - `WSLS`: 4.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-11-25 15:03:39

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `7`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `69.72%`
- **Durchschnittliche Kooperationsrate:** `33.13%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 418.53

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 28.0%
  - `Polarized`: 23.0%
  - `Cooperator (ALLC)`: 23.0%
  - `TFT-like`: 14.0%
  - `Cautious Coop.`: 10.5%
  - `WSLS`: 1.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-11-25 15:59:52

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `8`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `68.09%`
- **Durchschnittliche Kooperationsrate:** `32.03%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 408.21

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 30.0%
  - `Cooperator (ALLC)`: 28.0%
  - `Polarized`: 18.5%
  - `TFT-like`: 11.0%
  - `Cautious Coop.`: 8.5%
  - `WSLS`: 4.0%
- **Anzahl Cluster pro Strategietyp:**
  - `Polarized`: 1

---

## Simulationslauf vom: 2025-11-25 16:23:06

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `8`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

## Simulationslauf vom: 2025-11-25 16:23:27

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

### Finale Ergebnisse (des obigen Laufs)

**Globale Metriken (Gesamtsystem):**
- **System-Effizienz (% des Max):** `70.14%`
- **Durchschnittliche Kooperationsrate:** `33.55%`

**Metriken pro Agententyp (Durchschnitt über den gesamten Zeitraum):**
- **Avg. Reward/Match:**
  - `QLearningAgent`: 420.54

**Finale Cluster-Analyse:**
- **Anzahl gefundener Cluster:** `1`
- **Gesamtfläche pro Strategietyp:**
  - `Defector`: 26.5%
  - `Cooperator (ALLC)`: 23.5%
  - `Polarized`: 22.0%
  - `Cautious Coop.`: 12.0%
  - `TFT-like`: 11.5%
  - `WSLS`: 4.5%
- **Anzahl Cluster pro Strategietyp:**
  - `Defector`: 1

---

## Simulationslauf vom: 2025-11-25 17:03:14

### Globale Parameter
- **Begegnungsschema:** `SpatialGridScheme`
- **Gittergröße:** `(10, 20)`
- **Anzahl Matches/Duelle:** `200000`
- **Runden pro Episode:** `200`
- **Zufalls-Seed:** `9`

### Agenten-Population
- **QL:** `200`
- **Gesamt:** `200` Agenten

### Lern-Hyperparameter
- **alpha:** `0.05`
- **gamma:** `0.95`
- **epsilon:** `1.0`
- **epsilon_decay:** `0.9995`
- **min_epsilon:** `0.001`

---

